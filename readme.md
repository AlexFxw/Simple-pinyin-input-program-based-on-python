# 拼音输入法报告

### 计64 范轩玮 2016011334

## 问题描述

给定有限长度的拼音串输入，求解其对应的汉语句子输出。可以理解为对于一个给定的拼音串$S = s_0s_1s_2…s_k$，存在对应的汉语串$W = w_0w_1w_2…w_k$，拼音输入法的问题相当于求出概率最大的字符串$P(W) = \prod_{i=1}^kp(w_i|w_{i-1})$。经过分析建模后发现，这个问题转可以使用一阶隐马尔科夫模型求解，以下简单定义何谓一阶隐马尔科夫模型以及其与拼音输入法的相关性。

#### 一阶隐马尔科夫(Hiden Markov Model, HMM)

有若干个不可见状态$\{x_0, x_1, x_2,..,x_s\}$经由概率矩阵转化成可见的输出集合$\{y_0, y_1, y_3,…,y_k\}$，描述一个HMM模型需要三个重要的参数：

- 每个隐状态$x_i$之间的转移概率，可以表示为概率矩阵，由于马尔科夫假设模型的当前状态只与前一个状态有关。所以隐状态转移可以描述为一个s阶的正方阵A，元素$a_{ij}$代表二元串$x_ix_j$出现的概率。
- 隐状态为$x_i$时可见状态为$y_j$的概率，在HMM中称之为发射概率。
- 初始状态概率矩阵。

由于本问题所求的是根据可见状态求概率最大的隐状态，初始概率并不是必须的。

#### 输入法模型

在我的拼音输入法中，从可见状态（拼音）求解对应的隐状态的核心算法是对发射概率和转移概率进行动态规划求得最大概率字符串，二者皆可通过对训练集进行统计便可得到。统计结果以json的形式储存于.txt档中，Python运行时读取并转换成字典，统计结果包含：

- 不同二元汉字组合在训练语料中出现的次数
- 二元组出现的总次数
- 不同汉字在训练语料中出现的次数
- 总字数
- 同一个（二元）拼音对应了那些（二元）字

有了这些结果，在运行时很容易可以得到$P(w_i|w_{i-1})$，需要特别注明的是虽然$P(w_i|w_{i-1}) = P(w_{i-1}w_i)/P(w_{i-1})$ 是条件概率的一般形式，然而由于在输入法中容易发生$w_{i-1}w_i$出现次数为0从而概率为0的情况，为了避免递归求最大概率时被过多地影响，我加入了拉普拉斯平滑，定义$P(w_i|w_{i-1}) = \lambda P(w_i ) + (1-\lambda)P(w_{i-1}w_i)/P(w_{i-1})$。$\lambda$ 选取为0.01，此外由于语料总量很大，计算时可能发生概率非常小而被python视为0（python的浮点数默认小于$10^{-17}$的小数为0），所以我以对数来表示概率。

而为了简化问题，将拼音输入假设为字的二元模型——每一个字出现的概率只与前一个字有关。如此一来可以透过对$P(w_i|w_{i-1})$ 做动态规划求得拼音串对应的最大概率句子。实现上我维护了三层字典$f[i][cur][last]$ ，代表着在第i个拼音时当前汉字为cur且前一个汉字为last的概率，f有以下对应关系：

$f[i][cur][last] = max(f[i-1][last][j]*P(cur|last))$

j是last前缀可能接的所有汉字，可以透过访问统计结果字典对应的键得到，当迭代到i的时候可以确保i以前的f都求解完了。当迭代结束到i = n的时候，再从n往回递归即可得到概率乘积最大的字符串。

## 实验结果

由于训练集来自于新浪新闻，实验后发现对于新闻句子的识别成功率大于一般性的句子，这一点在长句子时尤其明显。从新闻中随机选取的测试集的识别成功率将近40%（0.383838），然而对于包含其他生活用句、网路用语的测试集正确率就大大下降，仅剩余0.21，字正确率也有所下降，然而不像句正确率差异那么大，分别是0.83和0.74。以下列举了部分实验结果：

#### 部分成功样例

1. 深度学习技术推动了人工智能的发展
2. 清华大学计算机科学与技术系
3. 智能技术与系统国家重点实验室
4. 全国人民代表大会在北京人民大会堂隆重召开
5. 特朗普希望不久和中国国家主席面对面会晤
6. 广东的人口数量位居全国第一
7. 想要实现一切梦想的话
8. 就像阳光穿过黑夜
9. 鼓起勇气坚定向前
10. 我有一个苹果

可以看到，对于新闻中常出现的句子和名词我的输入法可以相对准确地判别，即便是第4句那样较长的句子仍然可以正确识别。而较短的生活化句子如同7-10也具有一定的准确率。

#### 部分失败样例

1. **仅用**的武侠小说非常精彩 （应为金庸）
2. 他养了一**直青瓦**当宠物（应为一只青蛙）
3. 这是世界上最好的**变成**语言（应为编程）
4. 臣妾做不到**阿**（应为啊）
5. 菩提本无**数**（应为树）
6. 我爱学习学习**时**我快乐（应为使）

从这些失败案例中可以看出我的输入法的两个主要问题：目光短浅、训练集不全面。例如对于1. 来说，武侠小说理应接的是金庸，然而由于他们在算法里并没有联系因而反倒识别出了在新闻行文中较常出现的「仅用」，3.也是一样的道理，编程语言是个常见的词，然而二元模型来看「变成」和「语言」出现的次数要大得多。至于2. 4. 5.则可能源于训练集多是新闻资料，新闻里「青瓦台」出现的次数「青蛙」多是完全有可能的，然而这却与我们日常使用的倾向相反。而感叹词「啊」在新闻中不常使用，即使生活中这是种很常见的用法，对于诗句「菩提本无树」也有类似的问题。

目光短浅的问题需要透过算法的改进（基于词的模型）来改善，而训练集的问题可以透过增添不同来源的语料（实际上透过pypinyin ，任一段汉字都可以当做标注过的资料）。

### 改进

基于以上的分析，我后来添加了中文维基百科作为语料，大小约莫为400MB。加入之后正确率略有上升2个百分点达到了22%，对于上面列出的句子也有所影响，列举部分如下：

#### 好的影响

1. 几乎处处收敛函数列的控制收敛定理——这一类充满数学专有名词的难句，在先前的版本里无法有效识别，加入维基百科之后由于其中对于一些数学知识的提及，成功地识别了这种比较难的句子。
2. 「qing wa」成功被识别为「青蛙」而非「青瓦」

#### 不好的影响

1. 智能技术**语**系统国家重点实验室——在先前的版本中成功识别的句子在这里失败了，推测可能是维基百科中提及「语系」、「术语」的次数相对新闻多上不少，导致二元组识别时不再成功识别出「与」。

从这几个例子可以看到，语料库对辨别成功率的影响和测试集是相关的，举例来说，如果测试集中包含相当多科学名词、专有名词，那么维基百科对于正确率的提高会很明显，然而由于同时也会造成原先的新闻句子正确率下降，所以如果测试集是全新闻句子，那么加入其它语料可能反而会有负面的影响。总体来说，对正确率的优化更多的还是应该在算法上，不过或许可以建立不同的统计词库，在得知测试集的性质时可以选择性地只用专门的词库，针对性地提高正确率。如果追求平均表现最优的话，在各个来源选取大小相近的语料训练应该会有最好的效果。

## 总结与心得

这次的输入法作业让我对于基本的搜索及动态规划在人工智能的应用有更好的体会，对于一个很广泛的题目「输入法」，从一开始的无从下手，一步一步地简化问题、提出模型，到最后实现了一个简单功能的过程也令人获益良多。而自己的输入法存在的诸多问题也让人清楚感受到市面上成熟的输入法公司背后强大的技术能力，举例而言，固然使用了字的二元组模型简化问题后成功实现了基本功能，然而目光短浅的问题相当严重，我认为这也不是靠字的三元组、四元组就可以根治的。如何使用基于词的模型？如何比动态规划更有效的训练算法？这些都是写代码时我所没有想到的。

此外我使用python的字典存储二元模型的结果，导致运行时消耗了大量的内存，递归求解时的速度也难以令人满意。不仅仅要实现功能还得优雅地实现功能，我觉得在这一点上我还有诸多需要改进的。以前比较少遇到这种运算量大资料量大的问题，对于内存控制以及常数优化并没有太多的琢磨。然而这次的作业让我切实感觉到内存管理的重要性，以及即使算法量级相同，常数的差距也足以很大地影响用户体验。这些不足客观体现了我与那些又快又小又准的成熟输入法的开发者之间的差距，希望往后能逐渐进步吧。

总而言之，谢谢助教与老师以输入法这个实现不难，但实现得好大有学问的项目作为人工智能的开篇作业，实验的过程里着实收获颇丰。

## 备注

>  一些有关于代码运行上需要特别注明的事

因为不想花太多时间处理中文编码的问题，我使用了先天对各国语言支持较好的python3 实现，且我import 了 pypinyin这个包来标记语料。运行时请使用python3，且确保pypinyin 有安装在python3的目录下。运行时指令如下：

```python
python3 pinyin.py ../data/input.txt ../data/output.txt
```

前者放输入文件，由一行一句由空格分隔的拼音所组成。后者放输出文件路径，pinyin.py会将运算完的结果写入output.txt。

此外为了方便测试新闻语料与普通语料间的不同，亦提供以下测试方式：

```
python3 pinyin.py ../data/test_1.txt
python3 pinyin.py ../data/test_news.txt
```

将输出路径参数缺省便会切换成测试模式，测试文件由一行拼音与一行参考答案交替组成的，测试模式会据此比较参考答案与计算出的结果并给出字（句子）正确率，逐行的比对情况也会在终端打印出来便于查看。其中测试文件组成如下：

- test_1.txt, test_2.txt — 马少平老师之前在群里传的测试集，包括新闻与生活语句（还有一些奇怪的句子），句正确率应该在0.22。
- test_news.txt — 从新闻中随机抽取的句子测试集，包含较多新闻行文，句正确率应该在0.40。